NVIDIA A100 GPUs come in two versions with 40GB and 80GB HBM2 memory. On Google Colab, the 40GB version is typically available.
A100 GPUs are deployed in A2 accelerator-optimized virtual machines (VMs). Each A2 VM supports up to 16 A100 GPUs, designed for high-performance workloads like machine learning training, inference, and computational tasks.
